---
layout: post
title: 关于 tun/tap 设备
date: 2011-06-19 23:30:06.000000000 -07:00
type: post
parent_id: '0'
published: true
password: ''
status: publish
categories:
- Linux Application
tags: []
meta:
  _publicize_pending: '1'
  original_post_id: '1679'
  _wp_old_slug: '1679'
author:
  login: wangcong2015
  email: wangcong@rocketmail.com
  display_name: wangcong2015
  first_name: ''
  last_name: ''
permalink: "/2011/06/19/%e5%85%b3%e4%ba%8e-tuntap/"
---
<p><!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd"><br />
<html><body></p>
<p>长期以来对tun和tap这对兄弟分不太清，今天下定决心研究了一下代码，总算是搞明白了。</p>
<p>首先它们都是从/dev/net/tun里ioctl出来的虚拟设备，一个是通过IFF_TUN，另一个是 IFF_TAP。最好的例子莫过于vpnc里面的代码了。</p>
<p>[c]<br />
int tun_open(char *dev, enum if_mode_enum mode)<br />
{<br />
        struct ifreq ifr;<br />
        int fd, err;</p>
<p>        if ((fd = open("/dev/net/tun", O_RDWR)) &lt; 0) {<br />
                error(0, errno,<br />
                        "can't open /dev/net/tun, check that it is either device char 10 200 or (with DevFS) a symlink to ../misc/net/tun (not misc/net/tun)");<br />
                return -1;<br />
        }</p>
<p>        memset(&amp;ifr, 0, sizeof(ifr));<br />
        ifr.ifr_flags = ((mode == IF_MODE_TUN) ? IFF_TUN : IFF_TAP) | IFF_NO_PI;<br />
        if (*dev)<br />
                strncpy(ifr.ifr_name, dev, IFNAMSIZ);</p>
<p>        if ((err = ioctl(fd, TUNSETIFF, (void *)&amp;ifr)) &lt; 0) {<br />
                close(fd);<br />
                return err;<br />
        }<br />
        strcpy(dev, ifr.ifr_name);<br />
        return fd;<br />
}<br />
[/c]</p>
<p>用的ioctl的命令都是同一个TUNSETIFF。</p>
<p>虽然是出自一个娘，但它们仍然有大的不同。tun是点对点的设备，而tap是一个普通的以太网卡设备。也就是说，tun设备其实完全不需要有物理地址的！它收到和发出的包不需要arp，也不需要有数据链路层的头！而tap设备则是有完整的物理地址和完整的以太网帧。</p>
<p>用一个实际的例子来验证一下：</p>
<pre>
tap0      Link encap:Ethernet  HWaddr 0E:78:39:78:E7:A7
          inet addr:192.168.1.109  Bcast:192.168.1.255  Mask:255.255.255.0
          inet6 addr: fe80::c78:39ff:fe78:e7a7/64 Scope:Link
          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
          RX packets:0 errors:0 dropped:0 overruns:0 frame:0
          TX packets:0 errors:0 dropped:21 overruns:0 carrier:0
          collisions:0 txqueuelen:500
          RX bytes:0 (0.0 b)  TX bytes:0 (0.0 b)

tun0      Link encap:UNSPEC  HWaddr 00-00-00-00-00-00-00-00-00-00-00-00-00-00-00-00
          inet addr:X.X.X.X  P-t-P:X.X.X.X  Mask:255.255.255.255
          UP POINTOPOINT RUNNING NOARP MULTICAST  MTU:1412  Metric:1
          RX packets:6 errors:0 dropped:0 overruns:0 frame:0
          TX packets:6 errors:0 dropped:0 overruns:0 carrier:0
          collisions:0 txqueuelen:500
          RX bytes:690 (690.0 b)  TX bytes:402 (402.0 b)

% ethtool -i tun0
driver: tun
version: 1.6
firmware-version: N/A
bus-info: tun
% ethtool -i tap0
driver: tun
version: 1.6
firmware-version: N/A
bus-info: tap
</pre>
<p>继续回来看代码。还是vpnc的代码 tunip.c，看它发送的时候做了什么处理：</p>
<p>[c]<br />
static int tun_send_ip(struct sa_block *s)<br />
{<br />
        int sent, len;<br />
        uint8_t *start;</p>
<p>        start = s-&gt;ipsec.rx.buf;<br />
        len   = s-&gt;ipsec.rx.buflen;</p>
<p>        if (opt_if_mode == IF_MODE_TAP) {<br />
#ifndef __sun__<br />
                /*<br />
                 * Add ethernet header before s-&gt;ipsec.rx.buf where<br />
                 * at least ETH_HLEN bytes should be available.<br />
                 */<br />
                struct ether_header *eth_hdr = (struct ether_header *) (s-&gt;ipsec.rx.buf - ETH_HLEN);</p>
<p>                memcpy(eth_hdr-&gt;ether_dhost, s-&gt;tun_hwaddr, ETH_ALEN);<br />
                memcpy(eth_hdr-&gt;ether_shost, s-&gt;tun_hwaddr, ETH_ALEN);</p>
<p>                /* Use a different MAC as source */<br />
                eth_hdr-&gt;ether_shost[0] ^= 0x80; /* toggle some visible bit */<br />
                eth_hdr-&gt;ether_type = htons(ETHERTYPE_IP);</p>
<p>                start = (uint8_t *) eth_hdr;<br />
                len += ETH_HLEN;<br />
#endif<br />
        }</p>
<p>        sent = tun_write(s-&gt;tun_fd, start, len);<br />
        if (sent != len)<br />
                syslog(LOG_ERR, "truncated in: %d -&gt; %dn", len, sent);<br />
        hex_dump("Tx pkt", start, len, NULL);<br />
        return 1;<br />
}<br />
[/c]</p>
<p>从上面的代码我们很容易看出：</p>
<p>1. 所谓发送就是对/dev/net/tun进行写操作。对称的，所谓接收就是读操作。<br />
2. 如果是tap设备，发送时还要多加一个以太网的头。</p>
<p>我们再看内核中对应的代码是怎么处理的，在drivers/net/tun.c 中的 tun_get_user()：</p>
<p>[c]<br />
        switch (tun-&gt;flags &amp; TUN_TYPE_MASK) {<br />
        case TUN_TUN_DEV:<br />
                if (tun-&gt;flags &amp; TUN_NO_PI) {<br />
                //...<br />
                }</p>
<p>                skb_reset_mac_header(skb);<br />
                skb-&gt;protocol = pi.proto;<br />
                skb-&gt;dev = tun-&gt;dev;<br />
                break;<br />
        case TUN_TAP_DEV:<br />
                skb-&gt;protocol = eth_type_trans(skb, tun-&gt;dev);<br />
                break;</p>
<p>[/c]</p>
<p>内核直接忽略了 tun 设备的以太网帧。现在，整个流程我们就已经很清楚了。</p>
<p>可是，上面只是用vpnc的例子。我们知道，实际中像kvm虚拟机才是tap的使用大户，我们很有必要看一下kvm是怎么使用tap设备的。为了方便起见，我们不看 qemu-kvm，因为它的代码过于复杂，我们看一个简单的kvm tools的实现。</p>
<p>这部分的主要代码在 virtio/net.c里面，virtio_net__tap_init()是在启动虚拟机时初始化tap设备的，然后启动两个线程分别监控tap设备的收发，代码是virtio_net_rx_thread()和virtio_net_tx_thread()，它们负责把进来的IO操作转换成对/dev/net/tun的读写。可是，IO操作是怎么进来的呢？这是关键。</p>
<p>顺着代码里的“针”一个个找下去，我们不难发现，IO操作是由kvm模拟出来的。首先它会把CPU指令中对应的IO操作进行转化，这部分在内核中，arch/x86/kvm/emulate.c::x86_emulate_insn()：</p>
<p>[c]<br />
        do_io_in:<br />
                c-&gt;dst.bytes = min(c-&gt;dst.bytes, 4u);<br />
                if (!emulator_io_permited(ctxt, ops, c-&gt;src.val, c-&gt;dst.bytes)) {<br />
                        emulate_gp(ctxt, 0);<br />
                        goto done;<br />
                }<br />
                if (!pio_in_emulated(ctxt, ops, c-&gt;dst.bytes, c-&gt;src.val,<br />
                                     &amp;c-&gt;dst.val))<br />
                        goto done; /* IO is needed */<br />
                break;</p>
<p>[/c]<br />
pio_in_emulated() 调用的 emulator_pio_in_emulated() 会进一步触发KVM_EXIT_IO：</p>
<p>[c]<br />
static int emulator_pio_in_emulated(int size, unsigned short port, void *val,<br />
                             unsigned int count, struct kvm_vcpu *vcpu)<br />
{<br />
        if (vcpu-&gt;arch.pio.count)<br />
                goto data_avail;</p>
<p>        trace_kvm_pio(0, port, size, 1);</p>
<p>        vcpu-&gt;arch.pio.port = port;<br />
        vcpu-&gt;arch.pio.in = 1;<br />
        vcpu-&gt;arch.pio.count  = count;<br />
        vcpu-&gt;arch.pio.size = size;</p>
<p>        if (!kernel_pio(vcpu, vcpu-&gt;arch.pio_data)) {<br />
        data_avail:<br />
                memcpy(val, vcpu-&gt;arch.pio_data, size * count);<br />
                vcpu-&gt;arch.pio.count = 0;<br />
                return 1;<br />
        }</p>
<p>        vcpu-&gt;run-&gt;exit_reason = KVM_EXIT_IO;<br />
        vcpu-&gt;run-&gt;io.direction = KVM_EXIT_IO_IN;<br />
        vcpu-&gt;run-&gt;io.size = size;<br />
        vcpu-&gt;run-&gt;io.data_offset = KVM_PIO_PAGE_OFFSET * PAGE_SIZE;<br />
        vcpu-&gt;run-&gt;io.count = count;<br />
        vcpu-&gt;run-&gt;io.port = port;</p>
<p>        return 0;<br />
}<br />
[/c]</p>
<p>内核部分结束，转到用户空间，用户空间的 vcpu 会捕捉到这个事件，在 kvm-cpu.c::kvm_cpu__start() 中：</p>
<p>[c]<br />
                case KVM_EXIT_IO: {<br />
                        bool ret;</p>
<p>                        ret = kvm__emulate_io(cpu-&gt;kvm,<br />
                                        cpu-&gt;kvm_run-&gt;io.port,<br />
                                        (u8 *)cpu-&gt;kvm_run +<br />
                                        cpu-&gt;kvm_run-&gt;io.data_offset,<br />
                                        cpu-&gt;kvm_run-&gt;io.direction,<br />
                                        cpu-&gt;kvm_run-&gt;io.size,<br />
                                        cpu-&gt;kvm_run-&gt;io.count);</p>
<p>                        if (!ret)<br />
                                goto panic_kvm;<br />
                        break;<br />
                }<br />
[/c]<br />
kvm__emulate_io() 就会调用在 virtio/net.c 注册的 virtio_net_pci_io_in()，数据就这样流向了 tap 网卡了。</body></html></p>
